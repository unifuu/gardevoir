---
title: RAG について
date: 2026-12-02
summary: 📝 RAG のメモ...
tags:
  - ai
  - agent
  - llm
  - rag
---

## 1. はじめに

検索拡張生成（Retrieval-Augmented Generation、略称：RAG）は、外部の信頼できるデータソースに基づいて回答を生成させることで、大規模言語モデル（LLM）の精度と信頼性を向上させるアーキテクチャフレームワークです。

LLM は強力な「推論エンジン」ですが、主に 2 つの制限に苦しんでいます。

1.  **知識のカットオフ（情報の鮮度）:** 内部知識は静的であり、トレーニングが終了した時点までの情報に限られます。
2.  **ハルシネーション（幻覚）:** 知識の欠落に直面した際、誤った情報を自信満々にでっち上げることがあります。

RAG は、モデルが回答を生成する前に特定の情報データベースを参照できるようにすることで、このギャップを埋めます。これは、学生が「教科書持ち込み可の試験」を受けるようなものです。

---

## 2. コアアーキテクチャ：RAG の仕組み

RAG のプロセスは、主に**インデックス作成（Indexing）**と**検索・生成（Retrieval & Generation）**の 2 つのフェーズに分けることができます。

### フェーズ 1：インデックス作成 (データ準備)

システムが質問に答える前に、外部データを処理して保存しておく必要があります。

1.  **ドキュメントのロード (Loading):** 様々なソース（PDF、HTML、API など）からデータをインポートします。
2.  **分割 / チャンキング (Splitting):** LLM のコンテキストウィンドウ（入力制限）に収まるように、大きなドキュメントを「チャンク」と呼ばれる小さな断片に分割します。
3.  **埋め込み / エンベディング (Embedding):** エンベディングモデルを使用して、これらのテキストチャンクを意味的な内容を表す数値ベクトルに変換します。
4.  **保存 (Storage):** 高速な類似性検索を可能にするために、これらのベクトルを**ベクトルデータベース**（例：Pinecone, ChromaDB）に保存します。

### フェーズ 2：検索と生成 (ワークフロー)

1.  **ユーザークエリ:** ユーザーがプロンプトを入力します。
2.  **クエリの埋め込み:** システムはユーザーの質問を数値ベクトルに変換します。
3.  **検索 (Retrieval):** システムはベクトルデータベースを検索し、数学的に質問と最も類似している（関連性の高い）テキストチャンクを見つけます。
4.  **拡張 (Augmentation):** システムは、「ユーザークエリ」と「検索されたコンテキスト（文脈情報）」を組み合わせて 1 つのプロンプトを作成します。
5.  **生成 (Generation):** LLM はこの拡張されたプロンプトを処理し、提供されたデータに基づいて事実に基づいた回答を生成します。

---

## 3. RAG スタックの主要コンポーネント

| コンポーネント           | 役割                                     | 具体例                                |
| :----------------------- | :--------------------------------------- | :------------------------------------ |
| **LLM**                  | テキストを生成する推論エンジン。         | GPT-4, Claude 3, Llama 3              |
| **ベクトルデータベース** | 検索可能なデータが保存される記憶領域。   | Pinecone, Milvus, Weaviate            |
| **エンベディングモデル** | テキストをベクトルに変換する翻訳機。     | OpenAI text-embedding-3, Cohere Embed |
| **オーケストレーター**   | すべてのコンポーネントを接続する接着剤。 | LangChain, LlamaIndex                 |

---

## 4. RAG 対 ファインチューニング

| 機能                   | RAG                          | ファインチューニング (Fine-Tuning)    |
| :--------------------- | :--------------------------- | :------------------------------------ |
| **知識のソース**       | 外部データ (ベクトル DB)     | 内部モデルの重み (パラメータ)         |
| **データの鮮度**       | リアルタイム更新が可能       | 再トレーニングが必要                  |
| **透明性**             | 引用元/ソースを提示可能      | ブラックボックス (明確なソースがない) |
| **最適なユースケース** | 事実に基づく情報の検索・回答 | 特定のスタイルやフォーマットの学習    |

---

## 5. RAG のメリット

- **精度:** 事実に基づいて回答を生成させる（グラウンディング）ことで、ハルシネーションを大幅に削減します。
- **コスト効率:** 新しいデータのためにモデルを再トレーニングするよりも安価です。
- **セキュリティ:** プライベートな企業データを、公共のトレーニングセットに組み込むことなくモデルに利用させることができます。
- **検証可能性:** 回答に使用した特定のドキュメントをシステムが引用・提示できます。

---

## 6. 課題と制限

- **検索品質:** 検索で無関係なデータが見つかった場合、回答も間違ったものになります（Garbage In, Garbage Out：ゴミが入ればゴミが出る）。
- **レイテンシ:** 検索ステップを追加するため、処理時間がわずかに増加します。
- **複雑さ:** ベクトルデータベースとエンベディングパイプラインの保守・運用が必要です。

---

## 7. 高度な RAG テクニック

パフォーマンスを向上させるために、開発者は以下のような高度な手法を使用します。

- **ハイブリッド検索 (Hybrid Search):** ベクトル検索と従来のキーワード検索を組み合わせる手法。
- **リランキング (Re-ranking):** 最も関連性の高いドキュメントを LLM に渡す前に、別のモデルを使って順位付けし直す手法。
- **クエリ拡張 (Query Expansion):** 検索結果を向上させるために、ユーザーの質問をより記述的な内容に書き換える手法。

---

Powered by Gemini.
